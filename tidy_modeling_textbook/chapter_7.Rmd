---
title: 'Chapter 7: A model workflow'
author: "Daniel L."
date: "01/25/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 7.1 WHERE DOES THE MODEL BEGIN AND END?

So far, when we have used the term “the model”, we have meant a structural equation that relates some predictors to one or more outcomes. Let’s consider again linear regression as an example.

It is important to focus on the broader modeling process, instead of only fitting the specific model used to estimate parameters. This broader process includes any preprocessing steps, the model fit itself, as well as potential post-processing activities. In this book, we will refer to this broader process as the model workflow and include in it any data-driven activities that are used to produce a final model equation.

In other software, such as Python or Spark, similar collections of steps are called pipelines. In tidymodels, the term “pipeline” already connotes a sequence of operations chained together with a pipe operator (such as %>%). Rather than using ambiguous terminology in this context, we call the sequence of computational operations related to modeling workflows.

## 7.2 WORKFLOW BASICS

The $\textbf{workflows}$ package allows the user to bind modeling and preprocessing objects together. Let’s start again with the Ames data and a simple linear model:

```{r}
library(tidymodels)  # Includes the workflows package
tidymodels_prefer()

lm_model <- 
  linear_reg() %>% 
  set_engine("lm")
```

A workflow always requires a parsnip model object:

```{r}
lm_workflow <- 
  workflow() %>% 
  add_model(lm_model)

print(lm_workflow)
```

Notice that we have not yet specified how this workflow should preprocess the data: $Preprocessor$: $None$.

If our model were very simple, a standard R formula can be used as a preprocessor
```{r}
lm_workflow <- 
  lm_workflow %>% 
  add_formula(Sale_Price ~ Longitude + Latitude)

print(lm_workflow)
```

Workflows have a fit() method that can be used to create the model. Using the objects created in Section 6.6:

```{r}
lm_fit <- fit(lm_workflow, ames_train)
lm_fit
```

We can also predict() on the fitted workflow:

```{r}
predict(lm_fit, ames_test %>% slice(1:3))
```

The predict() method follows all of the same rules and naming conventions that we described for the parsnip package in Section 6.3.

Both the model and preprocessor can be removed or updated:
```{r}
lm_fit %>% update_formula(Sale_Price ~ Longitude)
```

Note that, in this new object, the output shows that the previous fitted model was removed since the new formula is inconsistent with the previous model fit.

## 7.3 Adding RAW VARIABLES TO THE WORKFLOW

There is another interface for passing data to the model, the add_variables() function which uses a dplyr-like syntax for choosing variables. The function has two primary arguments: outcomes and predictors. These use a selection approach similar to the tidyselect back-end of tidyverse packages to capture multiple selectors using c().


```{r}
lm_workflow <- 
  lm_workflow %>% 
  remove_formula() %>% 
  add_variables(outcome = Sale_Price, predictors = c(Longitude, Latitude))
lm_workflow
```

The predictors could also have been specified using a more general selector, such as


predictors = c(ends_with("tude"))

One nicety is that any outcome columns accidentally specified in the predictors argument will be quietly removed. This facilitates the use of:

predictors = everything()

When the model is fit, the specification assembles these data, unaltered, into a data frame and passes it to the underlying function:

```{r}
fit(lm_workflow, ames_train)
```


## 7.4 HOW DOES A WORKFLOW USE THE FORMULA?

A workflow is a general purpose interface. When $\textbf{add_formula()}$ is used, how should the workflow pre-process the data? Since the preprocessing is model dependent, workflows attempts to emulate what the underlying model would do whenever possible. If it is not possible, the formula processing should not do anything to the columns used in the formula. Let’s look at this in more detail.

### TREE-BASED MODELS

When we fit a tree to the data, the parsnip package understands what the modeling function would do. For example, if a random forest model is fit using the $ranger$ or $randomForest$ packages, the workflow knows predictors columns that are factors should be left as-is.

As a counter example, a boosted tree created with the xgboost package requires the user to create dummy variables from factor predictors (since xgboost::xgb.train() will not). This requirement is embedded into the model specification object and a workflow using xgboost will create the indicator columns for this engine. Also note that a different engine for boosted trees, C5.0, does not require dummy variables so none are made by the workflow.

A number of multilevel models have standardized on a formula specification devised in the lme4 package. For example, to fit a regression model that has random effects for subjects, we would use the following formula:

```{r}
# library(lme4)
# data(Orthodont)
# lmer(distance ~ Sex + (age | Subject), data = Orthodont)
```

```{r}
library(survival)
parametric_model <- surv_reg() %>% set_engine("survival")
```

```{r}
parametric_workflow <- workflow() %>% 
  # Pass the data along as-is:
  add_variables(outcome = c(fustat, futime), predictors = c(age, rx)) %>% 
  add_model(parametric_model, 
            #This formula is given to the model
            formula = Surv(futime, fustat) ~ age + strata(rx))

parametric_fit <- fit(parametric_workflow, data = ovarian)

print(parametric_fit)
```

```{r}
?add_model()
```

## CREATING MULTIPLE WORKFLOWS AT ONCE

It can become tedious or onerous to create a lot of workflows from different sets of preprocessors and/or model specifications. To address this problem, the workflowset package creates combinations of workflow components. A list of preprocessors (e.g., formulas, dplyr selectors, or feature engineering recipe objects discussed in the next chapter) can be combined with a list of model specifications, resulting in a set of workflows.

As an example, let’s say that we want to focus on the different ways that house location is represented in the Ames data. We can create a set of formulas that capture these predictors:

```{r}
location <- list(
  longitude = Sale_Price ~ Longitude,
  latitude = Sale_Price ~ Latitude,
  coords = Sale_Price ~ Longitude ~ Latitude,
  neighborhood = Sale_Price ~ Neighborhood
)
```

These representations can be crossed with one or more models using the workflow_set() function. We’ll just use the previous linear model specification to demonstrate:

```{r}
library(workflowsets)
location_models <- workflow_set(preproc = location, models = list(lm = lm_model))
location_models
print(location_models$info[[1]])
print(extract_workflow(location_models, id = "coords_lm"))
```

Workflow sets are mostly designed to work with resampling, which is discussed in Chapter 10. In the object above, the columns option and result must be populated with specific types of objects that result from resampling. We will demonstrate this in more detail in Chapters 11 and 15.

In the meantime, let’s create model fits for each formula and save them in a new column called fit. We’ll use basic dplyr and purrr operations:

```{r}
location_models <- location_models %>% mutate(fit = map(info, ~ fit(.x$workflow[[1]], ames_train)))

location_models

print(location_models$fit[[1]])
```

## 7.7 Chapter Summary

In this chapter, you learned that the modeling process encompasses more than just estimating the parameters of an algorithm that connects predictors to an outcome. This process also includes preprocessing steps and operations taken after a model is fit. We introduced a concept called a model workflow that can capture the important components of the modeling process. Multiple workflows can also be created inside of a workflow set.


For the Ames data, the code used in the later chapter is:

```{r}
library(tidymodels)
data(ames)

ames <- mutate(ames, Sale_Price = log10(Sale_Price))

set.seed(123)
ames_split <- initial_split(ames, prop = 0.80, strata = Sale_Price)
ames_train <- training(ames_split)
ames_test  <-  testing(ames_split)

lm_model <- linear_reg() %>% set_engine("lm")

lm_wflow <- 
  workflow() %>% 
  add_model(lm_model) %>% 
  add_formula(Sale_Price ~ Longitude + Latitude)

lm_fit <- fit(lm_wflow, ames_train)
```

